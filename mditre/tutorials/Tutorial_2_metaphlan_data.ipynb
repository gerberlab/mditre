{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8d1d0b",
   "metadata": {},
   "source": [
    "# Tutorial 2: MDITRE workflow on Metaphlan-based data\n",
    "In this tutorial we demonstrate how to use MDITRE on shotgun metagenomics data obtained via Metaphlan, using the dataset from Kostic et al., (2015). The study from Kostic et al., (2015) tracked the microbiomes of 17 infants sampled over the first three years of life, with the infants being classified as either normal or having developed type 1 diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c77f6ad",
   "metadata": {},
   "source": [
    "## Loading and preprocessing the data\n",
    "The following files are required for the data loading step. For other optional files that are accepted by the software for data loading and optional preprocessing features, please refer to our user manual [here](https://github.com/gerberlab/mditre/blob/master/mditre/docs/config_doc.pdf).\n",
    "\n",
    "### Required files\n",
    "#### Abundance data\n",
    "A CSV file containing the microbial abundances, formatted with the first row providing OTU IDs and the first column providing sample IDs. See [here](./datasets/raw/t1d/diabimmune_t1d_metaphlan_table.txt) for the abundance data file for this dataset.\n",
    "\n",
    "#### Sample metadata\n",
    "A CSV file that specifies an associated subject ID and timepoint for each sample ID. See [here](./datasets/raw/t1d/t1d_sample_metadata.csv) for the sample metadata file for this dataset.\n",
    "\n",
    "#### Subject metadata\n",
    "A CSV file that gives information about each subject, (including the value of whatever variable will be used as the host outcome for prediction (e.g., normal or t1d). See [here](./datasets/raw/t1d/t1d_wgs_subject_data.csv) for the subject metadata file for this dataset.\n",
    "\n",
    "### Preparing a config file\n",
    "The software requires user-defined config file with the desired data loading and preprocessing options. A pre-defined config file for this dataset is found [here](./datasets/raw/t1d/t1d_benchmark.cfg). Looking into this file, one can see a section ```[data]``` that contains the flags specifying the locations of the required data files and also a ```[preprocessing]``` section with the optional data preprocessing flags, described in detail in our user manual. The following are the flags the user will always need to specify in the config file.\n",
    "\n",
    "- <strong>tag</strong>: A short string used to generate the filename of the processed dataset (written to the current directory) in the following format ```<tag>_dataset_object.pickle```\n",
    "- <strong>abundance_data</strong>: Location of the abundance data file\n",
    "- <strong>sample_metadata</strong>: Location of sample metadata file\n",
    "- <strong>subject_data</strong>: Location of subject metadata file\n",
    "- <strong>ref_metagenomics_tree</strong>: Location of the reference phylogenetic tree for metagenomic sequences (read using ete3 package which accepts a variety of tree formats like Newick as mentioned [here](http://etetoolkit.org/docs/latest/tutorial/tutorial_trees.html#reading-and-writing-newick-trees); used to extract phylogenetic distances between the OTUs that are required for the model. IF not specified, the default is the tree from metaphlan2 package located [here](https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/mpa_v30_CHOCOPhlAn_201901_species_tree.nwk).\n",
    "- <strong>data_type</strong>: '16s' or 'metaphlan', if not specified the default is '16s'.\n",
    "- <strong>outcome_variable</strong>: A string specifying which of the columns in the subject metadata table encodes the host status variable for prediction (For example, 'Case_Control').\n",
    "- <strong>outcome_positive_value</strong>: The value of the host status variable that corresponds to a 'positive' outcome (for example, 'case'; the choice doesn't affect the model and is just used for labeling outputs)\n",
    "\n",
    "### Running the data loading/preprocessing utility\n",
    "After defining the config file, we run the 'preprocess' utility, which produces a serialized python pickle object containing the pre-processed data, in this case ```t1d_kostic_dataset_object.pickle``` in the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "# Make sure to have mditre package installed via pip prior to this step!\n",
    "from mditre.data_utils import preprocess, ConfigParser, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location of the config file\n",
    "filename_metaphlan_data_cfg = './datasets/raw/t1d/t1d_benchmark.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file using ConfigParser package\n",
    "config_metaphlan = ConfigParser.ConfigParser()\n",
    "config_metaphlan.read(filename_metaphlan_data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess 16s data\n",
    "dataset_metaphlan = preprocess(config_metaphlan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c050c64",
   "metadata": {},
   "source": [
    "## Running the model on preprocessed data\n",
    "We are now ready to run the MDITRE model for analysis, which takes the pickle file with the preprocessing data from the previous step. Running the MDITRE model will output the following information.\n",
    "- The predictive ability of the model using F1 score as the quantitative measure\n",
    "- A serialized pickle object containing all the information needed to interpret and visualize the learned rules.\n",
    "\n",
    "### Quick start with default options\n",
    "We recommend running MDITRE using cross-validation to assess the generalization capability of the model. Since the pytorch multiprocessing module does not support running from a Jupyter notebook, we included a python script [here ](./model_run_tutorial.py) to run the model on the prepared dataset from the previous step using default configuration options on the command line. We provide the following command that executes the script and runs a 5-fold cross-validation procedure using multiprocessing (1 process per fold) and returns logs pertaining to some training diagnostics (useful for debugging) and finally the F1 score.\n",
    "\n",
    "```python -m torch.distributed.launch --nproc_per_node=5 model_run_tutorial.py --data ./datasets/t1d_agg_filtered_phylo.pickle --data_name kostic_test```\n",
    "\n",
    "The MDITRE software is optimized to run on a GPU. However, it can also run on a CPU. On a CPU, it should still take only a few minutes to run this example in multiprocessing mode. If the user has limited CPU cores, they can set the \"nproc_per_node\" to a lower number. The full description of the command line arguments accepted by the model code is located in the documentation [here](https://github.com/gerberlab/mditre/blob/master/mditre/docs/config_doc.pdf). A brief summary of the required options to be passed as arguments to the command are as follows.\n",
    "\n",
    "- <strong>nproc_per_node</strong>: Number of parallel processes to be used for cross-validation procedure\n",
    "- <strong>data</strong>: Location of the preprocessed data pickle file from the previous step\n",
    "- <strong>data_name</strong>: A string used to create output file directory\n",
    "- <strong>is_16s</strong>: Required if using 16S rRNA amplicon based dataset (omit if using metagenomics based data)\n",
    "\n",
    "After executing the above command successfully, you can find the final F1 score from the cross-validation (0.82) and also the saved pickle file containing the learned rule information here ```t1d_rules_dump.pickle```, which will be used in the following rule visualization tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6c3bf",
   "metadata": {},
   "source": [
    "## Rule Visualization via GUI Tutorial\n",
    "Now we demonstrate the rule visualization GUI (Graphical User Interface) capabilities of the MDITRE software. After successfully running the model code on a given dataset, the user can interactively explore the learned rules via the GUI. We show an example walkthrough of the GUI on the learned rules obtained from running the MDITRE model in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d118bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from mditre.rule_viz import *\n",
    "# Make the notebook pop up a separate matplotlib window (instead of displaying inline)\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65b9c3",
   "metadata": {},
   "source": [
    "### Specify the location of rule output pickle file output by the model code\n",
    "After a successful run of the model code, the software saves a pickle file with suffix \"rules_dump.pickle\" in a specified location. This file contains all the necessary data to visualize the learned rules via the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_path = './kostic_rules_dump.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7ad4e",
   "metadata": {},
   "source": [
    "### Load the pickle file\n",
    "The loaded file is a dictionary that will be input into the GUI code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(rules_path, 'rb') as f:\n",
    "    rule_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9c80b",
   "metadata": {},
   "source": [
    "### Invoke the RuleVisualizer utility\n",
    "This opens a separate window with the rule visualization. We describe the workflow in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cf01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = RuleVisualizer(rule_dict, './')\n",
    "rv.plot_log_odds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe42f8a",
   "metadata": {},
   "source": [
    "# Rule Visualizer workflow\n",
    "- After running the rule visualizer utlity as shown before, a separate window pops up showing the log-odds of all the learned rules as heatmaps. In this example, we see that the model was able to learn 1 rule (rule 1). The topmost panel shows the log-odds of individual rules. This is followed panel showing the predicted log-odds of each rule individually for each subject. Finally, a panel showing ground truth labels for each subject (no t1d vs t1d). A rule with positive log-odds is predictive of the positive outcome (in this case t1d) and vice-versa. As we can see, the learned rule can perfectly classify the subjects based on their outcomes. Next, in order to view the learned rules, one can click on the button (that says \"Click\").\n",
    "- Clicking on a button to the left of the heatmap of rule 1 opens a separate window. This window shows the text of the rules on the top, followed by a panel showing the detector activations for each subject as a heatmap. As we see, the rule is predictive of the 'no t1d' outcome and contains 3 detectors. We show the conjunction of all the detectors in a separate panel.\n",
    "- Next, the user can click on the button to the left of the detector heatmap, which opens a separate window showing the average rate of change of abundances (slope) over time for the 2 groups of subjects of the selected taxa (shown as a tree on the right), along with the heatmaps of the slope within the selected time window (days 155 - 477). <strong>Note, if the figure does not fit the screen, please click on \"Configure subplots\" button (located to the left of the zoom tool on the top left), and then click \"tight layout\" option.</strong> The purpose of this visualization is to allow the user to explore the differences in the temporal dynamics of the selected taxa both within and outside the selected time window between the subjects. One can see that the abundances of subjects with no t1d increase at a higher rate (colored towards red) than the ones with t1d (colored towrads blue) during the selected window.\n",
    "- We also provide a button located in the bottom right, which when clicked opens a separate window with the full phylogenetic tree of taxa. Using the zoom tool located at the top left of the new window, one can see the selected taxa (with red branches) in the context of the other nearby taxa in the full phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e77275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the GUI\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573ffd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
